{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fc0e75-58c9-4dcf-9288-602b825444a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (70.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shubh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aa483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "tf.Tensor(b'hello tensorflow!', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant(\"hello tensorflow!\")\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = 2\n",
    "y = 3\n",
    "z = tf.add(x, y, name ='Add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d07523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#direct dependency\n",
    "a = tf.multiply(8,5)\n",
    "b = tf.multiply(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794ac918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indirect dependency\n",
    "a = tf.multiply(8,5)\n",
    "b = tf.multiply(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1cd5081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#create a graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    z = tf.add(x, y , name='Add')\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca1fd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear default graph\n",
    "# tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec68dc",
   "metadata": {},
   "source": [
    "Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891008f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349fddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "a = tf.multiply(3, 3)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(a)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ba9d6",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4110ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.Variable(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0234e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random.normal([500,111], stddev =0.35), name =\"weights\")\n",
    "print(W.numpy())\n",
    "\n",
    "tf.compat.v1.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a2501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(1212)\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad25de1",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdabee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3098b34b",
   "metadata": {},
   "source": [
    "Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "094acad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Use placeholder as in TensorFlow 1.x\n",
    "x = tf.compat.v1.placeholder(\"float\", None)\n",
    "y = x + 3\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(y, feed_dict={x: 2.0})\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee05ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(y, feed_dict={x: 5})\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb46f4",
   "metadata": {},
   "source": [
    "Introducing TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9821b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(1,name='x')\n",
    "y = tf.constant(1,name='y')\n",
    "a = tf.constant(3,name='a')\n",
    "b = tf.constant(3,name='b')\n",
    "\n",
    "prod1 = tf.multiply(x,y, name='prod1')\n",
    "prod2 = tf.multiply(a,b,name='prod2')\n",
    "\n",
    "sum = tf.add(prod1,prod2,name='sum')\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "  writer = tf.compat.v1.summary.FileWriter(logdir='./graphs',graph=sess.graph)\n",
    "  print(sess.run(sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9fdbc",
   "metadata": {},
   "source": [
    "Creating a name scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994cc42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(1,name='x')\n",
    "y = tf.constant(1,name='y')\n",
    "a = tf.constant(3,name='a')\n",
    "b = tf.constant(3,name='b')\n",
    "\n",
    "with tf.compat.v1.name_scope(\"Product\"):\n",
    "    with tf.compat.v1.name_scope(\"prod1\"):\n",
    "        prod1 = tf.multiply(x, y, name=\"prod1\")\n",
    "    with tf.compat.v1.name_scope(\"prod2\"):\n",
    "        prod2 = tf.multiply(a, b, name=\"prod2\")\n",
    "\n",
    "with tf.compat.v1.name_scope(\"Sum\"):\n",
    "    sum_op = tf.add(prod1,prod2,name='sum')\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    writer = tf.compat.v1.summary.FileWriter('./graphs',sess.graph)\n",
    "    print(sess.run(sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e6fe7",
   "metadata": {},
   "source": [
    "Handwritten digit classification using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184ecb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\shubh\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  1.54 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.41 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.37 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.33 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.25 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.24 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.40 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.20 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.14 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.06 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.02 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.96 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.91 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.83 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.80 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.58 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.16 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.02 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.99 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.94 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.50 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.50 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.50 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:02<00:00,  1.83 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:02<00:00,  4.57 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.82 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\shubh\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_13004\\66921264.py:24: The name tf.data.make_one_shot_iterator is deprecated. Please use tf.compat.v1.data.make_one_shot_iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_13004\\66921264.py:24: The name tf.data.make_one_shot_iterator is deprecated. Please use tf.compat.v1.data.make_one_shot_iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_13004\\66921264.py:46: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_13004\\66921264.py:46: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5619, Accuracy: 0.8596\n",
      "Epoch 2, Loss: 0.1977, Accuracy: 0.9439\n",
      "Epoch 3, Loss: 0.1458, Accuracy: 0.9580\n",
      "Epoch 4, Loss: 0.1152, Accuracy: 0.9673\n",
      "Epoch 5, Loss: 0.0934, Accuracy: 0.9730\n",
      "Epoch 6, Loss: 0.0776, Accuracy: 0.9780\n",
      "Epoch 7, Loss: 0.0653, Accuracy: 0.9811\n",
      "Epoch 8, Loss: 0.0567, Accuracy: 0.9839\n",
      "Epoch 9, Loss: 0.0471, Accuracy: 0.9871\n",
      "Epoch 10, Loss: 0.0409, Accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Disable eager execution for TensorFlow 1.x style\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "mnist_data, mnist_info = tfds.load('mnist', split='train', as_supervised=True, with_info=True)\n",
    "\n",
    "# Normalize the images\n",
    "def normalize_img(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Prepare the dataset for training: batch and shuffle\n",
    "batch_size = 128\n",
    "mnist_data = mnist_data.map(normalize_img)\n",
    "mnist_data = mnist_data.cache() \\\n",
    "                       .shuffle(buffer_size=10000) \\\n",
    "                       .batch(batch_size) \\\n",
    "                       .repeat()  # Repeat the dataset for multiple epochs\n",
    "\n",
    "# Create an iterator for the dataset in TensorFlow 1.x style\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(mnist_data)\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# Define placeholders for input and output\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, 28, 28, 1], name=\"input\")  # Modified shape to include channel\n",
    "Y = tf.compat.v1.placeholder(tf.int64, [None], name=\"label\")\n",
    "\n",
    "# Flatten the input using Keras Flatten layer\n",
    "X_flattened = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "# Build the model using `tf.keras.layers.Dense`\n",
    "with tf.compat.v1.name_scope(\"Model\"):\n",
    "    layer_1 = tf.keras.layers.Dense(512, activation='relu')(X_flattened)\n",
    "    layer_2 = tf.keras.layers.Dense(256, activation='relu')(layer_1)\n",
    "    layer_3 = tf.keras.layers.Dense(128, activation='relu')(layer_2)\n",
    "    logits = tf.keras.layers.Dense(10)(layer_3)  # No activation for logits\n",
    "\n",
    "# Define loss and optimizer\n",
    "with tf.compat.v1.name_scope(\"Loss\"):\n",
    "    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "\n",
    "with tf.compat.v1.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Define accuracy metric\n",
    "with tf.compat.v1.name_scope(\"Accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize all variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "num_steps_per_epoch = mnist_info.splits['train'].num_examples // batch_size\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_accuracy = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for step in range(num_steps_per_epoch):\n",
    "            batch = sess.run(next_batch)\n",
    "            batch_x, batch_y = batch[0], batch[1]\n",
    "            \n",
    "            # Reshape batch_x to have 4D shape (batch_size, 28, 28, 1)\n",
    "            batch_x = batch_x.reshape(-1, 28, 28, 1)\n",
    "            \n",
    "            _, acc, l = sess.run([optimizer, accuracy, loss], feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            total_accuracy += acc\n",
    "            total_loss += l\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/num_steps_per_epoch:.4f}, Accuracy: {total_accuracy/num_steps_per_epoch:.4f}')\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b74797",
   "metadata": {},
   "source": [
    "Math operations in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4ef29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_9420\\4010323645.py:5: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed702f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b798601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.constant([1.,2.,3.])\n",
    "y = tf.compat.v1.constant([3.,2.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c456c57",
   "metadata": {},
   "source": [
    "Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dc57b",
   "metadata": {},
   "source": [
    "Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1133b70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = tf.add(x,y)\n",
    "sum.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e988f1",
   "metadata": {},
   "source": [
    "Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bba767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  0.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = tf.subtract(x,y)\n",
    "difference.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad187552",
   "metadata": {},
   "source": [
    "Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19c36e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = tf.multiply(x,y)\n",
    "product.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a79b3f",
   "metadata": {},
   "source": [
    "Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d567b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333334, 1.        , 3.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division = tf.divide(x,y)\n",
    "division.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d151014",
   "metadata": {},
   "source": [
    "Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b335a898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product = tf.reduce_sum(tf.multiply(x,y))\n",
    "\n",
    "dot_product.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3763b0f",
   "metadata": {},
   "source": [
    "Finding the index of min and max element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([10,0,13,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdf077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index of min value:\n",
    "tf.argmin(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441cec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index of max value:\n",
    "tf.argmax(x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae28e9",
   "metadata": {},
   "source": [
    "Squared Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3004dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   4,  16,  36, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.compat.v1.Variable([1,3,5,7,11])\n",
    "y = tf.compat.v1.Variable([1])\n",
    "\n",
    "tf.math.squared_difference(x,y).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8816c9",
   "metadata": {},
   "source": [
    "Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96749527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,  27, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x^x\n",
    "x = tf.compat.v1.Variable([1,2,3,4])\n",
    "tf.pow(x,x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be438ade",
   "metadata": {},
   "source": [
    "Rank of the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98081370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.compat.v1.constant([[[1,2,4],[3,4,5]],\n",
    "             [[1,2,4],[3,4,5]]])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a86214c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 4],\n",
       "        [3, 4, 5]],\n",
       "\n",
       "       [[1, 2, 4],\n",
       "        [3, 4, 5]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cdc07",
   "metadata": {},
   "source": [
    "Reshape the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7441dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.constant([[1,2,3,4],[5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b79d7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[8,1]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23ac8f",
   "metadata": {},
   "source": [
    "Transpose the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c870a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
       "array([[1, 5],\n",
       "       [2, 6],\n",
       "       [3, 7],\n",
       "       [4, 8]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34690c8",
   "metadata": {},
   "source": [
    "Typecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23368cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88def1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bce0c0",
   "metadata": {},
   "source": [
    "Concatenating two matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "022f78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[3,6,9], [7,7,7]]\n",
    "y = [[4,5,6], [5,5,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c870441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 6, 9],\n",
       "       [7, 7, 7],\n",
       "       [4, 5, 6],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate row-wise\n",
    "tf.concat([x,y],0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa6988fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 6, 9, 4, 5, 6],\n",
       "       [7, 7, 7, 5, 5, 5]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate column-wise:\n",
    "tf.concat([x,y],1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a784db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 7],\n",
       "       [6, 7],\n",
       "       [9, 7]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack x matrix:\n",
    "tf.stack(x, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1a4b4",
   "metadata": {},
   "source": [
    "Reduce Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc75a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.compat.v1.Variable([[1.0,5.0], [2.0,3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb609277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [2., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "924ecb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute average values \n",
    "tf.reduce_mean(input_tensor=x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b2c1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 4. ], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average across the row\n",
    "tf.reduce_mean(input_tensor=x, axis =0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdf0c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3. ],\n",
       "       [2.5]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average across the column\n",
    "tf.reduce_mean(input_tensor=x,axis=1,keepdims=True).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0ba8e",
   "metadata": {},
   "source": [
    "Reduce Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3048654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [2., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31a5a634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 8.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum values across rows\n",
    "tf.reduce_sum(x,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48c7173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 5.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum values across columns\n",
    "tf.reduce_sum(x,1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3a32491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum all the values:\n",
    "tf.reduce_sum(x,[0,1]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c763d",
   "metadata": {},
   "source": [
    "Drawing Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e1c549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.590439 , 11.161395 ],\n",
       "       [13.4485035,  9.709789 ],\n",
       "       [ 8.874537 , 11.036206 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drawing values from normal the normal distribution:\n",
    "tf.random.normal(shape=(3,2),mean=10.0,stddev=2.0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffc314fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8945638 , 0.7832072 ],\n",
       "       [0.5405601 , 0.95168924],\n",
       "       [0.8249128 , 0.19475007]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drawing values from uniform distribution\n",
    "tf.random.uniform(shape=(3,2), minval=0, maxval=None,dtype=tf.float32,).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6b2b9",
   "metadata": {},
   "source": [
    "Create 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "212a5ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([5,5]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7818bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros_like(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb2171e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([5,5]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbda667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones_like(x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3f86d",
   "metadata": {},
   "source": [
    "Compute Softmax Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6775c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8756006 , 0.00589975, 0.11849965], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([7.,2.,5.])\n",
    "tf.nn.softmax(x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51138f8",
   "metadata": {},
   "source": [
    "Create Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbb50a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "i_matrix = tf.eye(7)\n",
    "print(i_matrix.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1293c",
   "metadata": {},
   "source": [
    "L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34c6d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79259396, 0.22645542, 0.56613857], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.l2_normalize(x,axis=None, epsilon=1e-12,).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9fbdd",
   "metadata": {},
   "source": [
    "Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb3373b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x,x)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    print(square(6.).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0741b",
   "metadata": {},
   "source": [
    "Bonjour Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a167b",
   "metadata": {},
   "source": [
    "Defining a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91960648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(13,input_dim=7,activation='relu'))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a1b99",
   "metadata": {},
   "source": [
    "Defining a functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9a2483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 315us/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 642us/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 750us/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1243573e2f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "data_test = np.array([[1, 2, 3, 4, 5, 6, 7], [2, 3, 4, 5, 6, 7, 8], [3, 4, 5, 6, 7, 8, 9]])\n",
    "labels_test = np.array([0, 1, 0])\n",
    "data = np.array([\n",
    "    [1, 2, 3, 4, 5, 6, 7],\n",
    "    [2, 3, 4, 5, 6, 7, 8],\n",
    "    [3, 4, 5, 6, 7, 8, 9],\n",
    "    [4, 5, 6, 7, 8, 9, 10],\n",
    "])\n",
    "labels = np.array([0, 1, 0, 1])\n",
    "\n",
    "input = Input(shape=(7,))\n",
    "layer1 = Dense(10,activation='relu')(input)\n",
    "layer2 = Dense(1,activation='relu')(layer1)\n",
    "output = Dense(1, activation='sigmoid')(layer2)\n",
    "#create the model\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "#compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(x=data, y=labels, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe259d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6931 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6931 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931471824645996, 0.5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(x=data_test,y=labels_test)\n",
    "model.evaluate(x=data, y=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327f457",
   "metadata": {},
   "source": [
    "MNIST digit classification using TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5625c0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 61s 5us/step\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5919 - accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2876 - accuracy: 0.9176\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2349 - accuracy: 0.9328\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.9423\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1740 - accuracy: 0.9499\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1540 - accuracy: 0.9561\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1381 - accuracy: 0.9605\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1245 - accuracy: 0.9643\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1135 - accuracy: 0.9680\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1036 - accuracy: 0.9706\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11064107716083527, 0.96670001745224]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist= tf.keras.datasets.mnist\n",
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = tf.cast(x_train/255.0, tf.float32), tf.cast(x_test/255.0,\n",
    "tf.float32)\n",
    "y_train, y_test = tf.cast(y_train,tf.int64),tf.cast(y_test,tf.int64)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=\n",
    "['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
